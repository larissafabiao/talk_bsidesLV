# And what if it was hacked? Tactics and Impacts of Adversarial Machine Learning

Este repositório contém os materiais e exemplos da talk **"And what if it was hacked? Tactics and Impacts of Adversarial Machine Learning"**, apresentada por **Larissa Fonseca**. A palestra explora os riscos de ataques adversariais aplicados a sistemas de Machine Learning e discute as principais ameaças que isso representa para as empresas.

---

## Sobre a Talk

### Resumo
De acordo com o relatório anual do World Economic Forum:  
> _"Aproximadamente metade dos executivos afirmam que os avanços em capacidades adversariais (phishing, malware, deepfakes) representam o impacto mais preocupante da IA generativa na cibersegurança."_  

Vivemos em uma era onde a implementação de IA é acelerada para acompanhar a evolução tecnológica, mas muitas vezes à custa da segurança. Esta palestra foi projetada para explorar como ataques adversariais podem ser aplicados a sistemas de aprendizado de máquina (ML) e os riscos que isso acarreta para empresas de diferentes setores.

### Contexto Detalhado
Desde cedo, Larissa foi fascinada pelo impacto e pelas possibilidades da inteligência artificial. Inspirada pela pergunta "E se alguém hackeasse isso?", ela aprofundou seus estudos no impacto que um sistema vulnerável de IA poderia ter na sociedade, como a manipulação de algoritmos de carros autônomos.  
Mais recentemente, com a popularização da IA e a compreensão das vulnerabilidades, Larissa direcionou sua pesquisa para ataques adversariais e Jailbreaks, explorando como esses ataques são compartilhados em fóruns e utilizados para manipular produtos que muitos acreditam ser seguros.

Nesta talk, Larissa apresenta:
- **Introdução a ataques adversariais contra IA**: incluindo evasão, extração de modelos, ataques de envenenamento e backdoors.
- **Funcionamento de Jailbreaks**: explorando como adversários utilizam técnicas para burlar restrições de IAs populares.
- **Demonstrações práticas**: vídeos e exemplos de ataques recentes, destacando a importância de mitigar riscos no desenvolvimento de sistemas de IA.

---

## Sobre a Palestrante

**Larissa Fonseca** é uma entusiasta de cibersegurança desde jovem, iniciando sua jornada em competições de *Capture The Flag* aos 12 anos. Formada em Sistemas de Informação, Larissa trabalhou como Analista de Riscos de Cibersegurança em uma grande fintech brasileira e atualmente estrutura a equipe interna de cibersegurança de uma das maiores empresas de inteligência de ameaças da América Latina.  

Seu foco atual está em especializar-se em segurança ofensiva, com ênfase em ataques adversariais em IA, combinando sua paixão por aprendizado contínuo com uma abordagem prática e ética.

Conecte-se com Larissa no [LinkedIn](https://www.linkedin.com/in/larissa-fonseca/).

---

> _Os códigos presentes nesse repositório foram criados por AIs puramente com o propósito investigativo, conforme apresentado na palestra_  
